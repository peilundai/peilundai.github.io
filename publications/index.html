<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Peilun Dai | publications</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Peilun</strong> Dai
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <a class="page-link" href="/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
            <a class="page-link" href="/teaching/">teaching</a>
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">publications by categories in reversed chronological order</h5>
  </header>

  <article class="post-content publications clearfix">
    
<h3 class="year">2017</h3>
<ol class="bibliography"><li>

<div id="Ma2017MultilayerLM">
  
    <span class="title">Multi-layer linear model for top-down modulation of visual attention in natural egocentric vision</span>
    <span class="author">
      
        
          
            
              
                Ma, Keng Teck,
              
            
          
        
      
        
          
            
              
                Li, Liyuan,
              
            
          
        
      
        
          
            
              <em>Dai, Peilun</em>,
            
          
        
      
        
          
            
              
                Lim, Joo-Hwee,
              
            
          
        
      
        
          
            
              
                Shen, Chengyao,
              
            
          
        
      
        
          
            
              
                and Zhao, Qi
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>2017 IEEE International Conference on Image Processing (ICIP)</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Top-down attention plays an important role in guidance of human attention in real-world scenarios, but less efforts in computational modeing of visual attention has been put on it. Inspired by the mechanisms of top-down attention in human visual perception, we propose a multi-layer linear model of top-down attention to modulate bottom-up saliency maps actively. The first layer is a linear regression model which combines the bottom-up saliency maps on various visual features and objects. A contextual dependent upper layer is introduced to tune the parameters of the lower layer model adaptively. Finally, a mask of selection history is applied to the fused attention map to bias the attention selection towards the task related regions. Efficient learning algorithm with single-pass polynomial complexity is derived. We evaluate our model on a set of natural egocentric videos captured from a wearable glass in real-world environments. Our model outperforms the baseline and state-of-the-art bottom-up saliency models.</p>
  </span>
  
</div>
</li>
<li>

<div id="yoon2017feasibility">
  
    <span class="title">Feasibility of 3D reconstruction of neural morphology using expansion microscopy and barcode-guided agglomeration</span>
    <span class="author">
      
        
          
            
              
                Yoon, Young-Gyu,
              
            
          
        
      
        
          
            
              <em>Dai, Peilun</em>,
            
          
        
      
        
          
            
              
                Wohlwend, Jeremy,
              
            
          
        
      
        
          
            
              
                Chang, Jae-Byum,
              
            
          
        
      
        
          
            
              
                Marblestone, Adam H,
              
            
          
        
      
        
          
            
              
                and Boyden, Edward S
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Frontiers in computational neuroscience</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We here introduce and study the properties, via computer simulation, of a candidate automated approach to algorithmic reconstruction of dense neural morphology, based on simulated data of the kind that would be obtained via two emerging molecular technologies-expansion microscopy (ExM) and in-situ molecular barcoding. We utilize a convolutional neural network to detect neuronal boundaries from protein-tagged plasma membrane images obtained via ExM, as well as a subsequent supervoxel-merging pipeline guided by optical readout of information-rich, cell-specific nucleic acid barcodes. We attempt to use conservative imaging and labeling parameters, with the goal of establishing a baseline case that points to the potential feasibility of optical circuit reconstruction, leaving open the possibility of higher-performance labeling technologies and algorithms. We find that, even with these conservative assumptions, an all-optical approach to dense neural morphology reconstruction may be possible via the proposed algorithmic framework. Future work should explore both the design-space of chemical labels and barcodes, as well as algorithms, to ultimately enable routine, high-performance optical circuit reconstruction.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2016</h3>
<ol class="bibliography"><li>

<div id="Mandal2016">
  
    <span class="title">Trends in Machine and Human Face Recognition</span>
    <span class="author">
      
        
          
            
              
                Mandal, Bappaditya,
              
            
          
        
      
        
          
            
              
                Lim, Rosary Yuting,
              
            
          
        
      
        
          
            
              <em>Dai, Peilun</em>,
            
          
        
      
        
          
            
              
                Sayed, Mona Ragab,
              
            
          
        
      
        
          
            
              
                Li, Liyuan,
              
            
          
        
      
        
          
            
              
                and Lim, Joo Hwee
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em></em>
    
    
      2016
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Face recognition (FR) is a natural and intuitive way for human beings to identify or verify or at least get familiar and interact with other members of the community. Hence, human beings expect and endeavor to develop similar competency in machine recognition of human faces. Due to the rapid increase in computing power in recent decades and the need to automate the FR tasks for many applications, researchers from diverse areas like cognitive and computer sciences are making efforts in understanding how humans and machines recognize human faces respectively. Its application is innumerable (like access control, surveillance, social interactions, e-commerce, just to name a few). In this chapter we will review two aspects of FR: machine recognition of faces and how human beings recognize human faces. We will also discuss the recent benchmark studies, their protocols and databases for FR and psychophysical studies of FR abilities of human beings.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2015</h3>
<ol class="bibliography"><li>

<div id="ma2015unconstrained">
  
    <span class="title">Unconstrained ego-centric videos with eye-tracking data</span>
    <span class="author">
      
        
          
            
              
                Ma, Keng-Teck,
              
            
          
        
      
        
          
            
              
                Lim, Rosary,
              
            
          
        
      
        
          
            
              <em>Dai, Peilun</em>,
            
          
        
      
        
          
            
              
                Li, Liyuan,
              
            
          
        
      
        
          
            
              
                and Joo-Hwee, Lim
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em></em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2020 Peilun Dai.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'always';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">




  </body>

</html>
